{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:21:49.547025Z",
     "start_time": "2019-07-09T11:21:48.911995Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Load weights from TF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Note: A kernel with tf 1 is needed*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Download pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:31:49.536582Z",
     "start_time": "2019-07-09T11:31:48.973477Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded checkpoint from  https://storage.googleapis.com/mnasnet/checkpoints/mnasnet-a1.tar.gz . It is available as mnasnet-a1\n"
     ]
    }
   ],
   "source": [
    "# from https://github.com/tensorflow/tpu/blob/master/models/official/mnasnet/mnasnet_example.ipynb\n",
    "\n",
    "checkpoint_name = 'mnasnet-a1' #@param\n",
    "url = 'https://storage.googleapis.com/mnasnet/checkpoints/' + checkpoint_name + '.tar.gz'\n",
    "print('Downloading from ', url)\n",
    "\n",
    "!wget -nc {url}\n",
    "print('Unpacking')\n",
    "!tar -xvf {checkpoint_name}.tar.gz\n",
    "\n",
    "display.clear_output()\n",
    "print('Successfully downloaded checkpoint from ', url,\n",
    "      '. It is available as', checkpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:30:57.011178Z",
     "start_time": "2019-07-09T11:30:56.892234Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:36:09.411733Z",
     "start_time": "2019-07-09T11:35:57.332989Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-abd198877cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexport_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saved_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSERVING\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "export_dir = os.path.join(checkpoint_name, 'saved_model')\n",
    "\n",
    "with tf.Graph().as_default() as graph, tf.Session() as sess:\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\n",
    "\n",
    "    vars_global = tf.global_variables()\n",
    "    model_vars = {}    \n",
    "    # get their name and value and put them into dictionary\n",
    "    sess.as_default()\n",
    "    for var in vars_global:\n",
    "        try:\n",
    "            model_vars[var.name] = var.eval()\n",
    "        except:\n",
    "            print(\"For var={}, an exception occurred\".format(var.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:31:30.518186Z",
     "start_time": "2019-07-09T11:31:30.484630Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:54:05.735250Z",
     "start_time": "2019-07-09T11:54:05.524041Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(\"tf_weights.npy\", model_vars)\n",
    "!rm -rf mnasnet-a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer weights to TF2 keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:38:18.142426Z",
     "start_time": "2019-07-09T11:38:18.108613Z"
    }
   },
   "source": [
    "*Note: A kernel with tf 2 is needed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:29:38.582408Z",
     "start_time": "2019-07-09T18:29:38.229399Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:38:38.976330Z",
     "start_time": "2019-07-09T11:38:38.930555Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tf_weights.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-087ad20c4470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tf_weights.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tf_weights.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tf_weights = np.load('tf_weights.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:41:00.479947Z",
     "start_time": "2019-07-09T11:40:56.983296Z"
    }
   },
   "outputs": [],
   "source": [
    "from MnasNet_Functional import build_mnasnet_model\n",
    "\n",
    "model = build_mnasnet_model('mnasnet-a1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:41:04.405267Z",
     "start_time": "2019-07-09T11:41:04.360203Z"
    },
    "code_folding": [
     55
    ]
   },
   "outputs": [],
   "source": [
    "def verify_and_set(layer, block_id, tf_weights, tf_keys, curr_index, verbose):\n",
    "    name = layer.name\n",
    "    start = 'mnasnet-a1'\n",
    "    block_name = f'mnas_blocks_{block_id}'\n",
    "    \n",
    "    if name.endswith('depthwise_conv'):\n",
    "        key = '{}/mnas_net_model/{}/depthwise_conv2d'.format(start, block_name)\n",
    "        forward = 1\n",
    "    \n",
    "    elif name.endswith('se_reduce_conv') or name.endswith('se_expand_conv'):\n",
    "        key = '{}/mnas_net_model/{}/se/conv2d'.format(start, block_name)\n",
    "        forward = 2\n",
    "    \n",
    "    elif name.endswith('stem_conv') or name.endswith('head_conv'):\n",
    "        key = '{}/mnas_net_model/mnas_{}/conv2d'.format(start, name[:4])\n",
    "        forward = 1\n",
    "    \n",
    "    elif name.endswith('stem_conv'):\n",
    "        key = '{}/mnas_net_model/mnas_stem/conv2d'.format(start)\n",
    "        forward = 1\n",
    "    \n",
    "    elif name.endswith('conv'):\n",
    "        key = '{}/mnas_net_model/{}/conv2d'.format(start, block_name)\n",
    "        forward = 1\n",
    "\n",
    "    elif name.endswith('stem_conv_BN') or name.endswith('head_conv_BN'):\n",
    "        key = '{}/mnas_{}/batch_normalization'.format(start, name[:4])\n",
    "        forward = 4\n",
    "\n",
    "    elif name.endswith('BN'):\n",
    "        key = '{}/{}/batch_normalization'.format(start, block_name)\n",
    "        forward = 4\n",
    "    \n",
    "    elif name == 'FC':\n",
    "        key = '{}/mnas_net_model/mnas_head/dense'.format(start)\n",
    "        forward = 2\n",
    "\n",
    "    else:\n",
    "        if layer.variables != []:\n",
    "            raise ValueError(f'Layer \"{name}\" is not supported')\n",
    "        return curr_index\n",
    "    \n",
    "    weights = []\n",
    "    for i in range(curr_index, curr_index+forward):\n",
    "        if not tf_keys[i].startswith(key):\n",
    "            msg = 'For layer={}, an exception occurred\\n'\n",
    "            msg += \"\\ttf_index:\\t{}\\n\\taccess_key:\\t{}\\n\\treal_key:\\t{}\"\n",
    "            raise ValueError(msg.format(name, i, key, tf_keys[i]))\n",
    "        weights.append(tf_weights[tf_keys[i]])\n",
    "    layer.set_weights(weights)  \n",
    "\n",
    "    if verbose:\n",
    "        print(f'Processesd \"{name}\"')\n",
    "    return curr_index+forward\n",
    "\n",
    "\n",
    "def keras_set_weights_from_tf_model(model, tf_weights, verbose=False):\n",
    "    tf_index = 1\n",
    "    block_id = 0\n",
    "    b_chars = ('0',) * 2\n",
    "    tf_keys = list(tf_weights.keys())\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        name = layer.name\n",
    "        if name.startswith('block'):\n",
    "            if b_chars != (name[6], name[12]):\n",
    "                block_id += 1\n",
    "                b_chars = (name[6], name[12])\n",
    "        \n",
    "        tf_index = verify_and_set(\n",
    "            layer,\n",
    "            block_id,\n",
    "            tf_weights,\n",
    "            tf_keys,\n",
    "            tf_index,\n",
    "            verbose\n",
    "            )      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:41:08.391321Z",
     "start_time": "2019-07-09T11:41:08.314637Z"
    }
   },
   "outputs": [],
   "source": [
    "keras_set_weights_from_tf_model(model, tf_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:51:42.839553Z",
     "start_time": "2019-07-09T11:51:42.465947Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights('MnasNet_tf2_keras.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:41:33.665514Z",
     "start_time": "2019-07-09T11:41:33.499746Z"
    }
   },
   "outputs": [],
   "source": [
    "!wget -nc -q https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG -O panda.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:53:22.741799Z",
     "start_time": "2019-07-09T11:53:22.661233Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import pylab\n",
    "import PIL\n",
    "import numpy as np\n",
    "filename = 'panda.jpg'\n",
    "img = np.array(PIL.Image.open(filename).resize((224, 224))).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T11:53:36.083507Z",
     "start_time": "2019-07-09T11:53:26.844652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top class:  388  with Probability=  0.8776357\n",
      "Top 1 Prediction: 388, lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens, probs=0.877636\n",
      "Top 2 Prediction: 245, Tibetan mastiff, probs=0.002865\n",
      "Top 3 Prediction: 384, Madagascar cat, ring-tailed lemur, Lemur catta, probs=0.002584\n",
      "Top 4 Prediction: 296, American black bear, black bear, Ursus americanus, Euarctos americanus, probs=0.001733\n",
      "Top 5 Prediction: 222, Irish water spaniel, probs=0.001599\n"
     ]
    }
   ],
   "source": [
    "import common.imagenet as imagenet\n",
    "from scipy.special import softmax\n",
    "from MnasNet_Functional import build_mnasnet_model\n",
    "\n",
    "\n",
    "model = build_mnasnet_model('mnasnet-a1')\n",
    "model.load_weights('MnasNet_tf2_keras.h5')\n",
    "\n",
    "logits = model.predict(img[np.newaxis,...])\n",
    "\n",
    "top_class = np.argmax(logits)\n",
    "probs = softmax(logits)\n",
    "\n",
    "print(\"Top class: \", top_class, \" with Probability= \", probs[0][top_class])\n",
    "label_map = imagenet.create_readable_names_for_imagenet_labels()  \n",
    "for idx, label_id in enumerate(reversed(list(np.argsort(probs)[0][-5:]))):\n",
    "    print(\"Top %d Prediction: %d, %s, probs=%f\" % (idx+1, label_id, label_map[label_id], probs[0][label_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:37:09.076922Z",
     "start_time": "2019-07-09T18:37:05.478601Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the MnasNet tf.keras model.\n",
    "from MnasNet_Functional import build_mnasnet_model\n",
    "\n",
    "model = build_mnasnet_model('mnasnet-a1')\n",
    "model.load_weights('MnasNet_tf2_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:36:35.214085Z",
     "start_time": "2019-07-09T18:36:28.950593Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the TensorFlow Lite model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Test the TensorFlow model on random input data.\n",
    "tf_results = model(tf.constant(input_data))\n",
    "\n",
    "# Compare the result.\n",
    "for tf_result, tflite_result in zip(tf_results, tflite_results):\n",
    "    np.testing.assert_almost_equal(tf_result, tflite_result, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:37:15.507993Z",
     "start_time": "2019-07-09T18:37:09.926072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15515740"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"MnasNet.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T18:36:59.235712Z",
     "start_time": "2019-07-09T18:36:51.559517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3983064"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_mnasnet_model('mnasnet-a1',\n",
    "                            dict(normalize_input=False))\n",
    "model.load_weights('MnasNet_tf2_keras.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_model = converter.convert()\n",
    "open(\"MnasNet_quant.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Mnasnet Example.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
